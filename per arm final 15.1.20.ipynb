{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import collections\n",
    "\n",
    "\"\"\"\n",
    "    data_path : path for dataset\n",
    "    output_column_name : Column Name with labels\n",
    "    stochastic_param : list of 2 values float[p1,p2]-> p1 is the probability that right arm is user's choice,\n",
    "                        p2 is the probability that the user might have chosen the wrong arm\n",
    "\"\"\"\n",
    "\n",
    "class Evaluator():\n",
    "\n",
    "    def __init__(self, data_path, output_column_name,  print_params = {}, use_non_stationarity = False, sampling_fraction=0.1, stochastic_param = [1,0]):\n",
    "        df_original = pd.read_csv('news_user_context_timestamp.csv')\n",
    "        df_original = df_original.drop(columns =['user_id'])\n",
    "        #df_original.iloc[:,~df_original.columns.duplicated()]\n",
    "        df_original['article_id']=df_original['article_id'].astype(str)\n",
    "        all_columns = list(df_original.columns)\n",
    "        output_column_name = 'article_id'\n",
    "        input_columns = all_columns[:]\n",
    "        input_columns.remove(output_column_name)\n",
    "        print('input cols : ', len(input_columns))\n",
    "        x = df_original[input_columns].values\n",
    "        self.print_params = print_params\n",
    "        y=df_original[output_column_name].values\n",
    "        x_scaled=pd.DataFrame(x,columns = input_columns)\n",
    "        x_scaled['article_id']=y\n",
    "        \n",
    "\n",
    "        x_tr, x_test , y_tr, y_test = train_test_split(x_scaled,y,test_size=0.3,shuffle=False)\n",
    "        x_train ,x_valid,y_train, y_valid = train_test_split(x_tr,y_tr,test_size=0.3,shuffle=False)\n",
    "\n",
    "        self.x_tr = pd.DataFrame(x_tr, columns = input_columns)\n",
    "        self.y_tr = pd.DataFrame(y_tr, columns = [output_column_name])\n",
    "\n",
    "        self.df = pd.DataFrame(x_train, columns = input_columns)\n",
    "        self.y_train = pd.DataFrame(y_train, columns = [output_column_name])\n",
    "\n",
    "        self.df_valid = pd.DataFrame(x_valid, columns=input_columns)\n",
    "        self.y_valid = pd.DataFrame(y_valid, columns = [output_column_name])\n",
    "\n",
    "        self.df_test = pd.DataFrame(x_test, columns=input_columns)\n",
    "        self.y_test = pd.DataFrame(y_test, columns = [output_column_name])\n",
    "\n",
    "        self.total_train= self.df.copy(deep = True)\n",
    "        self.total_train['article_id']=self.y_train.copy(deep = True)\n",
    "\n",
    "        self.total_test= self.df_test.copy(deep = True)\n",
    "        self.total_test['article_id']=self.y_test.copy(deep = True)\n",
    "\n",
    "        print (\"Train Shape : \", self.df.shape ,self.y_train.shape)\n",
    "        print (\"Valid Shape :\", self.df_valid.shape, self.y_valid.shape)\n",
    "        print (\"Test Shape :\", self.df_test.shape,self.y_test.shape)\n",
    "        self.arm_column_name = output_column_name\n",
    "        self.logging_frequency = 1000\n",
    "        self.number_features_in_context = len(input_columns)\n",
    "        self.list_arms = df_original[self.arm_column_name].unique().tolist()\n",
    "\n",
    "        self.num_arms = len(self.list_arms)\n",
    "        print(self.num_arms)\n",
    "        self.stochastic_param = stochastic_param\n",
    "\n",
    "        random.seed(9001)\n",
    "\n",
    "        #Initially, the correct arm is the right arm, later this will change to simulate non stationarity\n",
    "        self.dict_true_arm_to_right_arm = {arm:arm for arm in self.list_arms}\n",
    "        self.use_non_stationarity = use_non_stationarity\n",
    "        self.non_stationarity_steps = 50000\n",
    "        self.non_stationarity_param = 0\n",
    "        \n",
    "        self.e = 0.2\n",
    "        self.decay = 0.998\n",
    "\n",
    "\n",
    "    def get_list_arms(self):\n",
    "        return self.list_arms\n",
    "\n",
    "    def get_number_features_in_context(self):\n",
    "        return self.number_features_in_context\n",
    "\n",
    "    def get_dataset_shape(self):\n",
    "        return self.df.shape\n",
    "\n",
    "    def evaluate(self, policy):\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        rewards = 0\n",
    "        rewards_test=0\n",
    "        total_possible_reward = len(self.df_test) + len(self.df_valid)\n",
    "        evaluated = 0\n",
    "        evaluated_test=0\n",
    "        match_found = False\n",
    "        row_reward=0\n",
    "        q=0\n",
    "        iterative_reward=[]\n",
    "\n",
    "#################################################TRAINING##################################################################\n",
    "        #BATCH FIT TRAINING ROWS\n",
    "        for index, row in self.df.iterrows():\n",
    "            q=q+1\n",
    "            if(q%100==0):\n",
    "                iterative_reward.append(row_reward)\n",
    "                row_reward = 0\n",
    "\n",
    "            state = row.tolist()[:]\n",
    "            y_value = self.y_train.iloc[index][0]\n",
    "            \n",
    "            import random\n",
    "            rand = random.uniform(0, 1)\n",
    "\n",
    "            if(rand < self.e):\n",
    "                selected_action =[]\n",
    "                self.e=self.e*self.decay\n",
    "                while len(selected_action) <1:\n",
    "                    temp =random.choice(self.list_arms)\n",
    "\n",
    "                    if(temp not in selected_action):\n",
    "                        selected_action.append(temp)\n",
    "            else:        \n",
    "                selected_action,bs = policy.get_action(state)\n",
    "                \n",
    "\n",
    "                \n",
    "            reward = 0\n",
    "\n",
    "\n",
    "            p1 = round(random.uniform(0,1), 1)\n",
    "            p2 = round(random.uniform(0,1), 1)\n",
    "            \n",
    "            match_found = False\n",
    "            \n",
    "            for i in range(1):\n",
    "                reward=0\n",
    "                \n",
    "                if selected_action[i]== y_value : #and p1>(1-self.stochastic_param[0]):\n",
    "                    match_found = True\n",
    "                    reward = 1\n",
    "                    row_reward+=1\n",
    "         \n",
    "                policy.update_model(reward,selected_action[i],state)\n",
    "\n",
    "            if match_found:\n",
    "                rewards += 1\n",
    "\n",
    "            evaluated += 1\n",
    "\n",
    "            if self.use_non_stationarity and evaluated % self.non_stationarity_steps == 0:\n",
    "                self.non_stationarity_param += 1\n",
    "                print (self.non_stationarity_param)\n",
    "\n",
    "\n",
    "            if evaluated % self.logging_frequency == 0 and evaluated!=0:\n",
    "                print(\"---------------------------------------------------------------------------------------------------------- \")\n",
    "                print('evaluated and frequency reached %d' % evaluated)\n",
    "                print('accuracy %f' % ( float(rewards) / evaluated ))\n",
    "                print(\"----------------------------------------------------------------------------------------------------------- \")\n",
    "\n",
    "\n",
    "#             state = row.tolist()[:]\n",
    "#             right_arm = self.y_train.iloc[index][0]\n",
    "#             policy.update_model(1,right_arm,state, True)\n",
    "# #             df_elements = self.df.sample(n=3)\n",
    "# #             for i, r in df_elements.iterrows():\n",
    "# #                 state = row.tolist()[:]\n",
    "# #                 arm = self.y_train.iloc[index][0]\n",
    "# #                 policy.update_model(0,arm,state, True)\n",
    "\n",
    "                \n",
    "#             #for a in self.list_arms:\n",
    "#                 #if(a!=right_arm):\n",
    "#                     #policy.update_model(0,right_arm,state, True)\n",
    "                    \n",
    "################################################VALIDATION####################################################################\n",
    "\n",
    "        for index, row in self.df_valid.iterrows():\n",
    "            q=q+1\n",
    "            if(q%100==0):\n",
    "                iterative_reward.append(row_reward)\n",
    "                row_reward = 0\n",
    "\n",
    "\n",
    "            state = row.tolist()[:]\n",
    "            y_value = self.y_valid.iloc[index][0]\n",
    "            \n",
    "            import random\n",
    "            rand = random.uniform(0, 1)\n",
    "\n",
    "            if(rand < self.e):\n",
    "                selected_action =[]\n",
    "                self.e=self.e*self.decay\n",
    "                while len(selected_action) <1:\n",
    "                    temp =random.choice(self.list_arms)\n",
    "                    if(temp not in selected_action):\n",
    "                        selected_action.append(temp)\n",
    "            else:        \n",
    "                selected_action,bs = policy.get_action(state)\n",
    "                \n",
    "            reward = 0\n",
    " \n",
    "\n",
    "            p1 = round(random.uniform(0,1), 1)\n",
    "            p2 = round(random.uniform(0,1), 1)\n",
    "            \n",
    "            match_found = False\n",
    "            \n",
    "            for i in range(1):\n",
    "                reward=0\n",
    "                \n",
    "                if selected_action[i]== y_value : \n",
    "                    match_found = True\n",
    "                    reward = 1\n",
    "                    row_reward+=1\n",
    "\n",
    "                policy.update_model(reward,selected_action[i],state)\n",
    "\n",
    "            if match_found:\n",
    "                rewards += 1\n",
    "\n",
    "            evaluated += 1\n",
    "\n",
    "            if self.use_non_stationarity and evaluated % self.non_stationarity_steps == 0:\n",
    "                self.non_stationarity_param += 1\n",
    "                print (self.non_stationarity_param)\n",
    "\n",
    "\n",
    "            if evaluated % self.logging_frequency == 0 and evaluated!=0:\n",
    "                print(\"---------------------------------------------------------------------------------------------------------- \")\n",
    "                print('evaluated and frequency reached %d' % evaluated)\n",
    "                print('accuracy %f' % ( float(rewards) / evaluated ))\n",
    "                print(\"----------------------------------------------------------------------------------------------------------- \")\n",
    "\n",
    "##################################################TESTING##################################################################\n",
    "        precision=0\n",
    "        dict_impressions = {}\n",
    "        dict_clicks = {}\n",
    "        \n",
    "        for k in self.list_arms:\n",
    "            dict_impressions[k]=0\n",
    "            dict_clicks[k]=0\n",
    "            \n",
    "        tr=0\n",
    "        \n",
    "       \n",
    "        for index, row in self.df_test.iterrows():\n",
    "            \n",
    "            \n",
    "                q=q+1\n",
    "                if(q%100==0):\n",
    "                    iterative_reward.append(row_reward)\n",
    "                    row_reward = 0\n",
    "\n",
    "                state = row.tolist()[:]\n",
    "                y_value = self.y_test.iloc[index][0]\n",
    "                \n",
    "                import random\n",
    "                rand = random.uniform(0, 1)\n",
    "\n",
    "                if(rand < self.e):\n",
    "                    selected_action =[]\n",
    "                    self.e=self.e*self.decay\n",
    "                    while len(selected_action) <1:\n",
    "                        temp =random.choice(self.list_arms)\n",
    "                        if(temp not in selected_action):\n",
    "                            selected_action.append(temp)\n",
    "                            \n",
    "                else: \n",
    "                    selected_action,bs= policy.get_action(state)\n",
    "                    tr=tr+bs\n",
    "                \n",
    "                reward = 0\n",
    "\n",
    "\n",
    "       \n",
    "            \n",
    "            # Use probability p for stochasticity\n",
    "                p1 = round(random.uniform(0,1), 1)\n",
    "                p2 = round(random.uniform(0,1), 1)\n",
    "                ps=0\n",
    "                ps_sum = 0\n",
    "\n",
    "\n",
    "                match_found = False\n",
    "                for i in range(1):\n",
    "                    reward=0\n",
    "                    dict_impressions[selected_action[i]] += 1\n",
    "                    \n",
    "                    \n",
    "                    if selected_action[i] == y_value:\n",
    "                        row_reward+=1\n",
    "                        \n",
    "                        match_found = True\n",
    "                        reward = 1\n",
    "                        \n",
    "                        ps+=1\n",
    "                        ps_sum += ps/(i+1)\n",
    "                        dict_clicks[y_value] +=1\n",
    "\n",
    "                    \n",
    "                    policy.update_model(reward,selected_action[i],state)\n",
    "          \n",
    "            \n",
    "\n",
    "                if match_found:\n",
    "                    rewards += 1\n",
    "                    rewards_test += 1\n",
    "                evaluated += 1\n",
    "                evaluated_test+=1\n",
    "                precision =precision+ ps_sum\n",
    "\n",
    "                if self.use_non_stationarity and evaluated % self.non_stationarity_steps == 0:\n",
    "                    self.non_stationarity_param += 1\n",
    "                    print (self.non_stationarity_param)\n",
    "\n",
    "\n",
    "                if evaluated % self.logging_frequency == 0 and evaluated!=0:\n",
    "                    print(\"---------------------------------------------------------------------------------------------------------- \")\n",
    "                    print('evaluated and frequency reached %d' % evaluated)\n",
    "                    print('accuracy %f' % ( float(rewards) / evaluated ))\n",
    "                    print(\"----------------------------------------------------------------------------------------------------------- \")\n",
    "\n",
    "\n",
    "        #Total Reward\n",
    "        \n",
    "        with open('iterative_reward.pickle', 'wb') as handle:\n",
    "            pickle.dump(iterative_reward, handle)\n",
    "      \n",
    "        ctr = 0 \n",
    "        for key, value in dict_impressions.items():\n",
    "            if(value!=0):\n",
    "                ctr += dict_clicks[key]/value\n",
    "                \n",
    "        print (\"precision\")\n",
    "        print (precision/self.df_test.shape[0])\n",
    "        \n",
    "        print(\"CTR\")\n",
    "        print(ctr/len(dict_impressions.keys()))\n",
    "\n",
    "\n",
    "        print(\"accuracy\", float(rewards)/total_possible_reward)\n",
    "\n",
    "        print(\"---------------------------------\")\n",
    "\n",
    "        print(\"accuracy\", float(rewards_test)/evaluated_test)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        print (\"Total time taken by \",str(policy),\" = \",end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input cols :  37\n",
      "Train Shape :  (89421, 37) (89421, 1)\n",
      "Valid Shape : (38324, 37) (38324, 1)\n",
      "Test Shape : (54749, 37) (54749, 1)\n",
      "40\n",
      "WARNING:tensorflow:From /home/anubha/anaconda3/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 1000\n",
      "accuracy 0.021000\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 2000\n",
      "accuracy 0.021000\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 3000\n",
      "accuracy 0.022667\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 4000\n",
      "accuracy 0.024000\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 5000\n",
      "accuracy 0.025000\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 6000\n",
      "accuracy 0.025333\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 7000\n",
      "accuracy 0.024714\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 8000\n",
      "accuracy 0.025125\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 9000\n",
      "accuracy 0.025111\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 10000\n",
      "accuracy 0.025700\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 11000\n",
      "accuracy 0.026455\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 12000\n",
      "accuracy 0.026333\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 13000\n",
      "accuracy 0.026308\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 14000\n",
      "accuracy 0.026857\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 15000\n",
      "accuracy 0.027667\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 16000\n",
      "accuracy 0.028125\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 17000\n",
      "accuracy 0.028647\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 18000\n",
      "accuracy 0.029722\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 19000\n",
      "accuracy 0.030421\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 20000\n",
      "accuracy 0.030350\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 21000\n",
      "accuracy 0.030810\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 22000\n",
      "accuracy 0.030909\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 23000\n",
      "accuracy 0.031174\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 24000\n",
      "accuracy 0.031542\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 25000\n",
      "accuracy 0.031600\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 26000\n",
      "accuracy 0.031692\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 27000\n",
      "accuracy 0.032074\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 28000\n",
      "accuracy 0.032464\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 29000\n",
      "accuracy 0.032690\n",
      "----------------------------------------------------------------------------------------------------------- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 30000\n",
      "accuracy 0.032900\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 31000\n",
      "accuracy 0.033290\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 32000\n",
      "accuracy 0.033188\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 33000\n",
      "accuracy 0.033182\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 34000\n",
      "accuracy 0.033706\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 35000\n",
      "accuracy 0.033829\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 36000\n",
      "accuracy 0.033861\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 37000\n",
      "accuracy 0.033919\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 38000\n",
      "accuracy 0.033947\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 39000\n",
      "accuracy 0.033872\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 40000\n",
      "accuracy 0.034175\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 41000\n",
      "accuracy 0.034146\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 42000\n",
      "accuracy 0.034167\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 43000\n",
      "accuracy 0.034163\n",
      "----------------------------------------------------------------------------------------------------------- \n",
      "---------------------------------------------------------------------------------------------------------- \n",
      "evaluated and frequency reached 44000\n",
      "accuracy 0.034364\n",
      "----------------------------------------------------------------------------------------------------------- \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "#from eval_3_modified import Evaluator\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import itertools\n",
    "import operator\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "class TFNeuralNetworkRegressor():\n",
    "\n",
    "\tdef multilayer_perceptron(self, x, weights, biases, keep_prob):\n",
    "\t\t# Hidden fully connected layer1\n",
    "\t\tlayer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "\t\tlayer_1 = tf.nn.tanh(layer_1)\n",
    "\t\t# Hidden fully connected layer2\n",
    "\t\tlayer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "\t\tlayer_2 = tf.nn.relu(layer_2)\n",
    "\t\t# Hidden fully connected layer2\n",
    "# \t\tlayer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "# \t\tlayer_3 = tf.nn.relu(layer_3)\n",
    "\t\t# Output fully connected layer with a neuron for each class\n",
    "\t\tout_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "\t\treturn out_layer\n",
    "\n",
    "\tdef __init__(self, n_input, arm_name, model_number, training_dropout = 1.0, prediction_dropout = 1.0):\n",
    "\n",
    "\t\tself.n_input = n_input\n",
    "\t\tself.experience = []\n",
    "\t\tself.model_number = arm_name\n",
    "\t\tself.training_dropout = training_dropout\n",
    "\t\tself.prediction_dropout = prediction_dropout\n",
    "\n",
    "\t\t# Network Parameters\n",
    "\t\tn_hidden_1 = 60 # 1st layer number of neurons\n",
    "\t\tn_hidden_2 = 40 # 2nd layer number of neurons\n",
    "# \t\tn_hidden_3 = 40 # 3rd layer number of neurons\n",
    "\n",
    "\t\tweights = {\n",
    "\t\t\t'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "\t\t\t'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "# \t\t\t'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "\t\t\t'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "\t\t}\n",
    "\t\tbiases = {\n",
    "\t\t\t'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "\t\t\t'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "# \t\t\t'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "\t\t\t'out': tf.Variable(tf.random_normal([1]))\n",
    "\t\t}\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t \n",
    "\t\t\t\n",
    "\n",
    "\t\tself.keep_prob = tf.placeholder(\"float\", name=\"keep_prob\")\n",
    "\n",
    "\t\tself.x = tf.placeholder(\"float\", [None, n_input])\n",
    "\t\tself.y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "\t\tself.predictions = self.multilayer_perceptron(self.x, weights, biases,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  self.keep_prob)\n",
    "\n",
    "\t\tself.cost = tf.reduce_mean(tf.square(self.predictions - self.y))\n",
    "\n",
    "\t\tself.train = tf.train.AdamOptimizer(0.008).minimize(self.cost)\n",
    "\n",
    "\t\tself.sess = tf.Session()\n",
    "\n",
    "\t\tself.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\tdef get_samples_from_experience(self, must_have_row, must_have_column, n_samples=50):\n",
    "\t\tnum_to_sample = min(len(self.experience), n_samples)\n",
    "\t\tsample = random.sample(self.experience, num_to_sample)\n",
    "# \t\tprint (sample)\n",
    "\t\tx = [must_have_row]\n",
    "\t\ty = [must_have_column]\n",
    "\t\tfor row in sample:\n",
    "\t\t\tx.append(row[0])\n",
    "\t\t\ty.append(row[1])\n",
    "\t\tx = np.array(x).reshape(num_to_sample + 1, self.n_input)\n",
    "\t\ty = np.array(y).reshape(num_to_sample + 1, 1)\n",
    "\n",
    "\t\tif num_to_sample > 500:\n",
    "\t\t\tsm = SMOTE(random_state=42)\n",
    "\t\t\tX_res, y_res = sm.fit_sample(x, y)\n",
    "\t\t\ty_res = y_res.reshape(y_res.shape[0], 1)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tX_res, y_res = x, y\n",
    "\n",
    "\t\treturn X_res, y_res\n",
    "\n",
    "\tdef fit(self, X, Y):\n",
    "\t\tself.experience.append((X[0], Y))\n",
    "# \t\tprint(self.experience)# if len(self.experience)>1000:\n",
    "\t\t#     self.experience.pop(0)\n",
    "\t\t# forcing the experience sample to return this piece of information\n",
    "\n",
    "\t\t# Y = [Y]\n",
    "\t\tfor i in range(50):\n",
    "\t\t\tx, y = self.get_samples_from_experience(X[0], Y)\n",
    "\t\t\ttrain = self.sess.run([self.train],\n",
    "\t\t\t\t\t\t\t\tfeed_dict = {self.x:x, self.y:y, self.keep_prob:self.training_dropout})\n",
    "\n",
    "\tdef partial_fit(self, X, Y):\n",
    "\t\t# print \"Fitting\", self.model_number\n",
    "\t\tself.fit(X, Y)\n",
    "\n",
    "\tdef batch_fit(self, X, Y, iter = 1):\n",
    "\t\t# print \"Fitting : \", self.model_number\n",
    "\t\tfor i in range(0,iter):\n",
    "\t\t\ttrain = self.sess.run([self.train],\n",
    "\t\t\t\t\t\t\t\tfeed_dict = {self.x:X, self.y:Y, self.keep_prob:self.training_dropout})\n",
    "\n",
    "\tdef predict(self, X, verbose=False):\n",
    "\t\tpreds = self.sess.run([self.predictions],\n",
    "\t\t\t\t\t feed_dict = {self.x:X, self.keep_prob : self.prediction_dropout})\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(preds)\n",
    "\t\treturn preds\n",
    "\t\n",
    "class PerArmModelPolicy():\n",
    "\tdef __init__(self, list_arms, number_features_in_context, training_dropout, prediction_dropout, epsilon, number_models_per_arm=1,\n",
    "\t\t\t\tswitch_off_epsilon_exploration=True, use_epsilon_decay=True):\n",
    "\t\tself.list_arms = list_arms\n",
    "\t\tself.last_action = None\n",
    "\t\tself.last_reward = None\n",
    "\t\tself.last_state = None\n",
    "\t\tself.last_model = None\n",
    "\n",
    "\t\tself.experience = {}\n",
    "\t\tself.dict_arm_to_model = {}\n",
    "\t\t# self.epsilon_percentage = 10\n",
    "\t\t\t\t#If Using Batch Training\n",
    "\t\tself.batch_size = 0\n",
    "\t\tself.mini_batch = 500\n",
    "\t\tself.train_batch_size = 50000\n",
    "\n",
    "\t\t# if self.batch_size:\n",
    "\t\tself.iter = 0\n",
    "\t\tself.dict_update_hist = {}\n",
    "\t\tfor arm in list_arms:\n",
    "\t\t\tself.dict_arm_to_model[arm] = []\n",
    "\t\t\tfor i in range(number_models_per_arm):\n",
    "\t\t\t\tm = TFNeuralNetworkRegressor(number_features_in_context, arm, str(i), training_dropout, prediction_dropout)\n",
    "\t\t\t\tself.dict_arm_to_model[arm].append(m)\n",
    "\n",
    "\t\t# for epsilon decay\n",
    "\t\tself.num_feedback_received = 0\n",
    "\t\tself.decay = 50\n",
    "\t\tself.switch_off_epsilon_exploration = switch_off_epsilon_exploration\n",
    "\t\tself.use_epsilon_decay = use_epsilon_decay\n",
    "\t\tself.default_epsilon = epsilon\n",
    "\tdef get_best_arm(self, state):\n",
    "\t\tbest_score1 = 0\n",
    "\t\tbest_score2 = 0\n",
    "\t\tbest_score3 = 0\n",
    "\t\tbest_score4 = 0\n",
    "\t\tbest_score5 = 0\n",
    "\n",
    "\t\tbest_arm1 = None\n",
    "\t\tbest_arm2 = None\n",
    "\t\tbest_arm3 = None\n",
    "\t\tbest_arm4 = None\n",
    "\t\tbest_arm5 = None\n",
    "\n",
    "\t\tbest_model1 = None\n",
    "\t\tbest_model2 = None\n",
    "\t\tbest_model3 = None\n",
    "\t\tbest_model4 = None\n",
    "\t\tbest_model5 = None\n",
    "\n",
    "\t\ts=[best_score1,best_score2,best_score3, best_score4, best_score5]\n",
    "\t\ta=[best_arm1, best_arm2, best_arm3 , best_arm4, best_arm5]\n",
    "\t\tm=[best_model1 ,best_model2 , best_model3 ,best_model4, best_model5]\n",
    "\n",
    "\t\t#score_to_model = {}\n",
    "\n",
    "\t\tfor arm, models in self.dict_arm_to_model.items():\n",
    "\t\t\t# score = model.predict([state])[0]\n",
    "\t\t\ttry:\n",
    "\t\t\t\t# randomly sample a model from the list of models\n",
    "\t\t\t\tmodel = random.choice(models)\n",
    "\t\t\t\tscore = model.predict([state])[0]\n",
    "\t\t\t\t#score_to_arm[score] = arm\n",
    "\t\t\t\t# print(score)`\n",
    "\t\t\t\tif score > best_score1 or best_arm1 is None:\n",
    "\t\t\t\t\tbest_score5 = best_score4\n",
    "\t\t\t\t\tbest_score4 = best_score3\n",
    "\t\t\t\t\tbest_score3 = best_score2\n",
    "\t\t\t\t\tbest_score2 = best_score1\n",
    "\t\t\t\t\tbest_score1 = score\n",
    "\n",
    "\t\t\t\t\tbest_arm5= best_arm4\n",
    "\t\t\t\t\tbest_arm4 = best_arm3\n",
    "\t\t\t\t\tbest_arm3= best_arm2\n",
    "\t\t\t\t\tbest_arm2 = best_arm1\n",
    "\t\t\t\t\tbest_arm1 = arm\n",
    "\n",
    "\t\t\t\t\tbest_model5 = best_model4\n",
    "\t\t\t\t\tbest_model4 = best_model3\n",
    "\t\t\t\t\tbest_model3 = best_model2\n",
    "\t\t\t\t\tbest_model2 = best_model1\n",
    "\t\t\t\t\tbest_model1 = model\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t\telif score > best_score2 and score < best_score1 :\n",
    "\t\t\t\t\tbest_score5 = best_score4\n",
    "\t\t\t\t\tbest_score4 = best_score3\n",
    "\t\t\t\t\tbest_score3 = best_score2\n",
    "\t\t\t\t\tbest_score2 = score\n",
    "\n",
    "\n",
    "\t\t\t\t\tbest_arm5= best_arm4\n",
    "\t\t\t\t\tbest_arm4 = best_arm3\n",
    "\t\t\t\t\tbest_arm3= best_arm2\n",
    "\t\t\t\t\tbest_arm2 = arm\n",
    "\n",
    "\n",
    "\t\t\t\t\tbest_model5 = best_model4\n",
    "\t\t\t\t\tbest_model4 = best_model3\n",
    "\t\t\t\t\tbest_model3 = best_model2\n",
    "\t\t\t\t\tbest_model2 = model\n",
    "\n",
    "\t\t\t\telif score > best_score4 and score < best_score3:\n",
    "\t\t\t\t\tbest_score5 = best_score4\n",
    "\t\t\t\t\tbest_score4 = score\n",
    "\n",
    "\t\t\t\t\tbest_arm5= best_arm4\n",
    "\t\t\t\t\tbest_arm4 = arm\n",
    "\n",
    "\n",
    "\t\t\t\t\tbest_model5 = best_model4\n",
    "\t\t\t\t\tbest_model4 = model\n",
    "\n",
    "\t\t\t\telif score > best_score4 and score < best_score5:\n",
    "\t\t\t\t\tbest_score5 = best_score4\n",
    "\t\t\t\t\tbest_score4 = score\n",
    "\n",
    "\n",
    "\t\t\t\t\tbest_arm5= best_arm4\n",
    "\t\t\t\t\tbest_arm4 = arm\n",
    "\n",
    "\t\t\t\t\tbest_model5 = best_model4\n",
    "\t\t\t\t\tbest_model4 = model\n",
    "\n",
    "\t\t\t\telse: #score > best_score5:\n",
    "\t\t\t\t\tbest_score5 = score\n",
    "\t\t\t\t\tbest_arm5= arm\n",
    "\t\t\t\t\tbest_model5 = model\n",
    "\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint('model %s not ready yet' % arm)\n",
    "\t\t\t\tprint('----------------------------------')\n",
    "\t\t\t\t# print(repr(e))\n",
    "\t\t\t\t# sys.exit(1)\n",
    "\t\t\t\treturn s,a,m\n",
    "\t\t#print (type(best_arm))\n",
    "\t\ts=[best_score1,best_score2,best_score3, best_score4, best_score5]\n",
    "\t\ta=[best_arm1, best_arm2, best_arm3 , best_arm4, best_arm5]\n",
    "\t\tm=[best_model1 ,best_model2 , best_model3 ,best_model4, best_model5]\n",
    "\t\treturn s,a,m\n",
    "\n",
    "\tdef get_action(self, state):\n",
    "\t\texplore_action=[]\n",
    "\t\tfor i in range(5):\n",
    "\t\t\texplore_action.append(random.choice(list_arms))\n",
    "\t\t\t\n",
    "\t\tbest_score, best_action, best_model = self.get_best_arm(state)\n",
    "\t\tself.num_feedback_received += 1\n",
    "\t\tif self.use_epsilon_decay:\n",
    "\t\t\tepsilon = self.get_epsilon()\n",
    "\t\telse:\n",
    "\t\t\tepsilon = self.default_epsilon\n",
    "\t\t# if (not self.switch_off_epsilon_exploration) and (np.random.random() <= epsilon or best_action is None):\n",
    "\t\tif np.random.random() <= epsilon or best_action[0] is None:\n",
    "\t\t\taction = explore_action\n",
    "\t\telse:\n",
    "\t\t\t# print('chose best action')\n",
    "\t\t\taction = best_action\n",
    "\t\t# print(action)\n",
    "\t\t#self.last_action = action\n",
    "\t\t#print('action',self.last_action)\n",
    "\t\tbs=0\n",
    "\t\tfor i in best_score:\n",
    "\t\t\tbs=bs+i\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\tself.last_state = state\n",
    "\t\tself.last_model = best_model\n",
    "\t\treturn action, bs\n",
    "\n",
    "\n",
    "\tdef update_model(self, reward, last_action = None, last_state = [], update_in_train = False):\n",
    "\t\t# Immediate Updates for incremental training\n",
    "\t\tif not last_action:\n",
    "\t\t\tlast_action = self.last_action\n",
    "\t\tif not last_state:\n",
    "\t\t\tlast_state = self.last_state\n",
    "\t\tself.last_reward = reward\n",
    "\n",
    "\t\tif self.batch_size==0 and update_in_train == False and last_action!=None:\n",
    "\t\t\tself.last_reward = reward\n",
    "\t\t\tself.dict_arm_to_model[last_action][0].partial_fit([last_state], [self.last_reward])\n",
    "\n",
    "\t\t#Batch Updates for Li Hong Matching\n",
    "\t\tif update_in_train :\n",
    "\t\t\tif(self.iter == 0 or self.iter%self.train_batch_size != 0):\n",
    "\t\t\t\t#for i in range(0,self.num_locations):\n",
    "\t\t\t\tif last_action not in self.dict_update_hist.keys():\n",
    "\t\t\t\t\t\tself.dict_update_hist[last_action] = []\n",
    "\t\t\t\t\t\tself.dict_update_hist[last_action].append([])\n",
    "\t\t\t\t\t\tself.dict_update_hist[last_action].append([])\n",
    "\t\t\t\t\t\t#Storing Location\n",
    "\t\t\t\t\t\t#self.dict_update_hist[last_actions].append(i)\n",
    "\t\t\t\t\t\tself.dict_update_hist[last_action][0].append(last_state)\n",
    "\t\t\t\t\t\tself.dict_update_hist[last_action][1].append([self.last_reward])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.dict_update_hist[last_action][0].append(last_state)\n",
    "\t\t\t\t\tself.dict_update_hist[last_action][1].append([self.last_reward])\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint( \"Update Number: \", self.iter)\n",
    "\t\t\t\tfor iteration in range(1,7001):\n",
    "\t\t\t\t\tif(iteration%1000 == 0):\n",
    "\t\t\t\t\t\tprint (\"Iteration Number : \", iteration)\n",
    "\t\t\t\t\tfor offer, update in self.dict_update_hist.items():\n",
    "\t\t\t\t\t\tnum_to_sample = min(len(update[0]), self.mini_batch)\n",
    "\t\t\t\t\t\trandom_indices = random.sample(range(0, len(update[0])), num_to_sample)\n",
    "\t\t\t\t\t\tx_train = []\n",
    "\t\t\t\t\t\ty_train = []\n",
    "\t\t\t\t\t\tfor index in random_indices:\n",
    "\t\t\t\t\t\t\tx_train.append(update[0][index])\n",
    "\t\t\t\t\t\t\ty_train.append(update[1][index])\n",
    "\t\t\t\t\t\tself.dict_arm_to_model[offer][0].batch_fit(x_train, y_train)\n",
    "\n",
    "\t\t\t\t\t\t#self.dict_per_location_offer_model[update[2]][offer].batch_fit(x_train, y_train)\n",
    "\t\t\tself.iter+=1\n",
    "\n",
    "\n",
    "\tdef get_epsilon(self):\n",
    "\t\t\"\"\"Produce epsilon\"\"\"\n",
    "\t\ttotal = self.num_feedback_received\n",
    "\t\treturn float(self.decay) / (total + float(self.decay))\n",
    "\n",
    "\n",
    "\n",
    "training_dropout, prediction_dropout, epsilon= 0.5, 0.5, 0.0000001\n",
    "use_non_stationarity = False\n",
    "\n",
    "print_params = {}\n",
    "print_params[\"training_dropout\"] = training_dropout\n",
    "print_params[\"prediction_dropout\"] = prediction_dropout\n",
    "print_params[\"epsilon\"] = epsilon\n",
    "\n",
    "#Change these in the function get_samples_from_experience too\n",
    "print_params[\"Sampling\"] = 50\n",
    "print_params[\"Number of times fit\"] = 10\n",
    "\n",
    "print_params[\"use_non_stationarity\"] = use_non_stationarity\n",
    "\n",
    "switch_off_epsilon_exploration = True\n",
    "forest_cover_evaluator = Evaluator('news_user_context_timestamp.csv', 'article_id', print_params, use_non_stationarity)\n",
    "list_arms = forest_cover_evaluator.get_list_arms()\n",
    "number_features_in_context = forest_cover_evaluator.get_number_features_in_context()\n",
    "per_arm_model_policy = PerArmModelPolicy(list_arms, number_features_in_context, training_dropout, prediction_dropout, epsilon,1,\n",
    "\t\t\t\t\t\t\t\t\t\tswitch_off_epsilon_exploration,\n",
    "\t\t\t\t\t\t\t\t\t\tFalse)\n",
    "forest_cover_evaluator.evaluate(per_arm_model_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
